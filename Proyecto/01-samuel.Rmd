```{r}
library(igraph)
library(curl)
library(tidyjson)
library(dplyr)
library(purrr)
library(tidyverse)
library(Matrix)
library(ggplot2)
```


# Analizando el *ssdeep*

Las funciones *hash* como *MD5*, *SHA256* o otras son útiles si queremos verificar la integridad de un archivo, su principio fundamental es que un pequeño cambio en el archivo (del orden de unos pocos bits) cambia la salida drásticamente.

En nuestro caso si queremos encontrar similitud entre *malware* no podemos usar esas funciones, porque si sabemos que un archivo es peligroso y tenemos su hash calculado, con cambiar un bit de ese archivo ya no lo podríamos detectar.

Por ello existe el programa *ssdeep*, que permite observar pequeñas diferencias entre archivos calculando el *CTPH* (parecido al *hash*).

Tenemos tres programas de ejemplo escritos en C, y queremos ver en qué porcentaje se parecen.

## sample1.c
```{c, eval=FALSE}
#include <stdio.h>

void main() {
  printf (“Hello World”);
}
```


## sample2.c
```{c, eval=FALSE}
#include <stdio.h>
int main(int argc, char *argv[]) {
for (int i = 0; i < 100; i++) {

        if (i%2 == 0) {
                i = i + 1;
        }
}
return 0;
}
```

## sample3.c
```{c, eval=FALSE}
#include <stdio.h>

void main() {
  int a = 5;
  printf (“Hello World: %d\n”, a);
}
```

Ahora calculamos y comparamos el *ssdeep* de los tres programas:

```{bash, eval=FALSE}
$ ssdeep -s * > sample_ctph.ssd
$ ssdeep -m sample_ctph.ssd -s *
```

Obtenemos lo siguiente:

```{bash, eval=FALSE}
$ sample1 matches sample_ctph.ssd:/home/samuel/Documentos/LCC/pruebas/sample1 (100)
$ sample1 matches sample_ctph.ssd:/home/samuel/Documentos/LCC/pruebas/sample2 (63)
$ sample1 matches sample_ctph.ssd:/home/samuel/Documentos/LCC/pruebas/sample3 (80)
```

sample1.c es mucho más parecido a sample3.c (en un 80%, mientras que solo un 63% con sample2.c). 

## Analizando los json

Primero cargamos el directorio Android y el dataframe preprocesado.

```{r, warning=FALSE}
path <- "~/Documentos/LCC/ProyectoVT/Proyecto/Android2/"
nombres_ficheros <- list.files(path)
df <- read_csv("~/Documentos/LCC/ProyectoVT/Proyecto/virusTotal.csv")
#df_deep <- read.csv("~/Documentos/LCC/ProyectoVT/Proyecto/analisis_ssdeep.csv")
```

Para analizar nuestros *json*, escribimos primero la siguiente función que para cada archivo saca su *sdeep* y crea un *dataframe*:

```{r}
# Entrada: json
# Salida: dataframe 
get_ssdeep <- function(x) {
  json <- read_json(x)
  res <- json %>% gather_object() %>% filter(name == 'ssdeep') %>% as.data.frame()  
  return (res)
}

# Por cada archivo en la carpeta Android
# coge su ssdeep y los guarda en un dataframe
df_deep <- data.frame()
for (i in nombres_ficheros) {
  df_deep <- rbind(df_deep, get_ssdeep(paste0(path,i)))
}

# Limpia el dataframe
df_deep <- df_deep %>% select(..JSON)
colnames(df_deep) <- ('ssdeep')
```

Leemos los dataframes, *df_deep* contiene los *hashes CTPH*:

```{r, warning=FALSE, eval=FALSE}


# Coge los virus cuya distancia (parecido)
# en sus ssdeep sea menor que 2
# y los guarda en *indices*
indices <- c()
for (i in 1:nrow(df_deep)) {
  for (j in (i+1):nrow(df_deep)) {
    if ( adist(df_deep[i,], df_deep[j,]) == 1) {
      indices <- c(indices, i,j)
      }
  }
}
```

### Matriz de adyacencias

Creamos una matriz de adyacencias con todos los json, donde la posicion Mij = 1 si la distancia entre los hashes del archivo *i* y el *1* es igual a uno. 

__Cuanto menor es la distancia, menos diferencia hay entre los hashes y más código comparten.__

```{r, eval=FALSE}
  n <- nrow(df)
  Mat <- matrix(0, nrow = n, ncol = n)
  colnames(Mat) <- c(1:n)
  row.names(Mat) <- c(1:n)
  j <- 1
  while(j < length(indices)) {
    Mat[indices[j], indices[j+1]] <- 1
    j <- j+2
  }
```



Ahora juntamos todo en la siguiente función:

```{r}
# Entrada: distancia entre json
# Salida: Grafo=(V,E) 
#         V = json
#         E = conexiones entre json con sus distancias como pesos
get_adj_matrix <- function(distancia) {
  
  indices <- c()
  distancias <- c()
  for (i in 1:nrow(df_deep)) {
    for (j in (i+1):nrow(df_deep)) {
      if ( adist(df_deep[i,], df_deep[j,]) <= distancia) {
        indices <- c(indices, i,j)
        distancias <- c(distancias, adist(df_deep[i,], df_deep[j,]))
      }
    }
  }
  
  n <- nrow(df)
  Mat <- matrix(0, nrow = n, ncol = n)
  colnames(Mat) <- c(1:n)
  row.names(Mat) <- c(1:n)
  j <- 1
  while(j < length(indices)) {
    Mat[indices[j], indices[j+1]] <- 1
    j <- j+2
  }

  G <- graph_from_adjacency_matrix(Mat, mode = 'undirected')
  G <- set_edge_attr(G, 'dist', value=distancias)
  
  return(G)
  
}
```


## Grafos

Dibujamos el siguiente grafo donde los vértices indican el json y las aristas su simulitud. Esto quiere decir que, por ejemplo, el grupo 147, 153 y 46 comparte gran parte de código. 

```{r}
G <- get_adj_matrix(1)

Isolated = which(degree(G)==0)
G2 = delete.vertices(G, Isolated)

plot(G2, vertex.color='#ADD8E6', 
     edge.curved = .1, 
     vertex.size=20,
     edge.label=E(G2)$dist,
     vertex.frame.color = NA,
     layout=layout_nicely
     )
title("Distancias <= 1",cex.main=1,col.main="Black")
```

## Grafo completo

Vamos a ver qué grafo se dibuja si restringimos menos la búsqueda y ponemos que saque todos los archivos que se parezcan como mínimo en un 60%.
Se pueden ver varios grupos que forman componentes y muchos otros nodos aislados. Esto puede deberse a que los componentes corresponden a alguna variantes del mismo malware.

```{r}
G1 <- get_adj_matrix(60)

plot(G1)
title("Grafo completo con distancia <= 60",cex.main=1,col.main="Black")

```

Calculamos los componentes y guardamos los nodos del más grande.

```{r}
c1 <- components(G1)
biggest1 <- which.max(c1$csize)
vids1 <- V(G1)[c1$membership==biggest1]

```

Dibujamos el subgrafo.

```{r}
plot(induced_subgraph(G1, vids1), edge.label=E(G1)$dist)
title("Mayor componente con pesos",cex.main=1,col.main="Black")

plot(induced_subgraph(G1, vids1), vertex.size=25)
title("Mayor componente sin pesos",cex.main=1,col.main="Black")

plot(induced_subgraph(G1, vids1),vertex.size = 5, vertex.color = "#1e3f66", vertex.frame.color = 'red', vertex.label.cex = .7,  vertex.label = NA, edge.curved = .5, edge.arrow.size = .3, edge.width = .7)
title("Mayor componente",cex.main=1,col.main="Black")
```

### Análisis del componente

Usando el algoritmo pagerank y la función grado, ordenamos los nodos por importancia:

```{r}
subgrafo <- induced_subgraph(G1, vids1)
pg <- page.rank(subgrafo)

importancia <- data.frame(
  grado = degree(subgrafo),
  page_rank = pg$vector
)
importancia_sorted <- data.frame(
  grado = sort(degree(subgrafo), decreasing = TRUE),
  page_rank = sort(pg$vector, decreasing = TRUE)
)

knitr::kable(head(importancia_sorted, 10))

```

Resaltamos los nodos con grado mayor que cincuenta:

```{r}
plot(subgrafo, vertex.size=ifelse(importancia[V(subgrafo),][1]>50,5, 1), vertex.label=NA, edge.curved = .5, edge.arrow.size = .3, edge.width = .7)
```


Si vemos los tamaños de los componentes, hay uno con doce nodos:

```{r}
c1$csize
```

Lo dibujamos, en este caso los json comparten aproximadamente la mitad de código.

```{r}
vids2 <- V(G1)[c1$membership==12]
plot(induced_subgraph(G1, vids2), edge.label=E(G1)$dist, vertex.size=20)
```



## Grafo de distancias <= 10

Calculamos y dibujamos las componentes del grafo con distancias menores o iguales que diez.
```{r}
G <- get_adj_matrix(10)

c <- components(G)
biggest <- which.max(c$csize)
vids <- V(G)[c$membership==biggest]
plot(induced_subgraph(G, vids), edge.label=E(G)$dist)
title("Distancias <= 10 con pesos",cex.main=1,col.main="Black")

plot(induced_subgraph(G, vids), vertex.size=25)
title("Distancias <= 10 sin pesos",cex.main=1,col.main="Black")

plot(induced_subgraph(G, vids),vertex.size = 10, vertex.color = "#1e3f66", vertex.frame.color = 'blue', vertex.label.cex = .7,  vertex.label = NA, edge.curved = .5, edge.arrow.size = .3, edge.width = .7)
title("Distancias <= 10",cex.main=1,col.main="Black")

```


## Análisis del mayor componente

Todos los archivos tienen el mismo tamaño, subidos desde California en menos de una hora. Con una media de 20  positivos, probablemente sean el mismo archivo.

```{r}
v <- as(vids, 'vector')

compare <- data.frame()
for (i in v) {
  compare <- rbind(compare, df[i,])
}

compare %>% select(size) %>% unique()
compare %>% select(submission.submitter_country) %>% unique()

times <- compare %>% select(first_seen, scan_date) %>% 
  mutate(first_seen = gsub('20[0-9]{2}-[0-9]+-[0-9]+', '', first_seen), scan_date = gsub('20[0-9]{2}-[0-9]+-[0-9]+', '', scan_date))
```

```{r}
lapply(times[,1], max)
lapply(times[,1], min)
```


Media y desviación típica

```{r}
# Media
compare %>% select(positives) %>% lapply(., mean)
```

```{r}
# Desviación típica
compare %>% select(positives) %>% lapply(., sd)
```


## Analizando los resultados de los antivirus

Vamos a ver qué resultado da cada antivirus a los json (vértices) del grafo anterior. Si dos antivirus dan el mismo resultado en archivos diferentes que sabemos que son casi iguales es probable que compartan motor.

La siguiente función recorre el directorio del dataset y crea un dataframe con los antivirus.
```{r, eval=FALSE}

# Entrada: Ruta al fichero
# Salida: Dataframe con resultados de los AV
get_results <- function(json) {
  
  json_data <- tidyjson::read_json(json)
  df_temp <- json_data %>% 
    gather_object() %>%   
    filter(name=='scans') %>% 
    spread_all() %>% 
    gather_object() %>% 
    select(ends_with('result')) %>% 
    .[1,] %>% 
    select(-last_col())
  
  
  return(df_temp) 
}


```



vids tiene los vértices de los grafos calculados. Pasamos los nombres a formato numérico con ceros a la izquierda.

```{r}
ficheros <- sapply(vids, function(x) paste0(sprintf("%04d", x), '.json') )
```

Creamos un dataframe y, por cada vértice, cogemos los escáneres.

```{r, eval=FALSE}
df_results <- data.frame()
for (i in ficheros) {
  df_results <- rbind.fill(df_results, get_results(paste0(path,i)))
}
write.csv(df_results, "~/Documentos/LCC/ProyectoVT/Proyecto/escaneres.csv")
```

Leemos y limpiamos el dataframe.

```{r, warning=FALSE, error=FALSE}
df_results <- read_csv("~/Documentos/LCC/ProyectoVT/Proyecto/escaneres.csv")
#df_results <- df_results %>% select(-..JSON)
colnames(df_results) <- lapply(colnames(df_results), function(x) gsub('.result', '', x))

# Quitar columnas enteras NA
df_results <- df_results[, colSums(is.na(df_results)) != nrow(df_results)]

df_results <- df_results %>% select(-...1)
```

Cogemos la columna trece, que no tiene valores NA. Como en realidad todas las columnas son el mismo archivo con ver una sola nos sirve, y podemos ver cómo cada antivirus (excepto los que comparten motor) lo clasifican de manera distinta.

```{r}
j107 <- df_results[13,]
j107 <- t(j107)
knitr::kable(j107, col.names = c('0107.json'))
```



Si seleccionamos los AV Kasperky y ZoneAlarm se observa fácilmente que los resultados son idénticos y seguramente compartan el mismo motor.

```{r}
df_results %>% select(Kaspersky, ZoneAlarm) %>% knitr::kable(.)
```


McAfee y McAfee GW Edition, normal porque ambos son de McAfee
```{r}
df_results %>% select(McAfee, `McAfee-GW-Edition`) %>% knitr::kable(.)
```



