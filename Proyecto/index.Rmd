--- 
title: "Virus Total"
author: "Samuel Sánchez Toca y Alejandro Medina Astorga"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  Este libro de bookdown contiene el proyecto LCC sobre analizar el dataset de VirusTotal.
link-citations: yes
github-repo: https://github.com/samuel-uma/ProyectoVT
---

# Preprocesado de datos

Este es el proyecto realizado por Samuel Sánchez Toca y Alejandro Medina Astorga para la asignatura Laboratorio de Computación Científica para el dataset **VirusTotal**.

## Inicio 

Primero tuvimos que analizar los datos que recibimos los cuales venian en archivos .json por lo que teniamos que extraerlos de estos archivos y al tener tantas columnas decidir cuales de estas eran mas útiles para su posterior analisis.

Para el preprocesado, hemos usado las librerías *jsonlite, tidyjson, jsonlite* y *tidyverse* para manejar los archivos. El dataset consta de casi doscientos ficheros *json* con la información obtenida al analizarlos con distintos antivirus, el primer paso es, por tanto, ver cómo están estructurados los datos para decidir con qué información nos vamos a quedar.

## Renombrando los archivos

El siguiente *script* cambia los nombres a los archivos para facilitar su uso para hacer pruebas:

```
a=1
for i in *.json; do
	new=$(printf "%04d.json" "$a")
	mv -i -- "$i" "$new"
	let a=a+1
done

```

## Datos iniciales

Primero, obtenemos los nombres de todos los archivos y los guardamos en la variable *nombres_ficheros*:

```{r eval=FALSE}
path <- "~/Documentos/LCC/ProyectoVT/Proyecto/Android2"
nombres_ficheros <- list.files(path)
```


Empezamos importando el primer fichero, usando la función *read_json* de la librería *tidyjson* obtenemos:
```{r eval=FALSE}

json_0001 <- tidyjson::read_json(paste0(path, "/0001.json"))

```

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

## Preprocesado

Como indicamos antes, lo primero que hicimos fue leer el primer json para tener una idea de que es lo que tenemos
que hacer.
```{r}
library(curl)
library(tidyjson)
library(dplyr)
library(purrr)
library(tidyverse)
library(kableExtra)

json_data <- tidyjson::read_json("~/LCC/ProyectoVT/Proyecto/Android2/0001.json")

tbl <- json_data %>%
  spread_all()
tbl
```
como vemos, usamos el spread_all para obtener todas las variables.

Ahora vamos a hacer lo mismo pero con todos los ficheros json a la vez:

```{r}
#path <- "~/GitHub/VirusTotal/ProyectoVT/Proyecto/Android2"
path <- "~/LCC/ProyectoVT/Proyecto/Android2"
nombres_ficheros <- list.files(path)

j <- 0
df <- data.frame()
for (i in nombres_ficheros) {
  filepath <- file.path(path, paste0(i))
  i <- tidyjson::read_json(filepath)
  nombre <- paste0('f_', j)
#  assign(nombre, i)
  tbl <- i %>% spread_all(recursive = TRUE)
  nombre_l <- tbl %>%
    select(scan_date,first_seen,total,size,times_submitted,positives,
           submission.submitter_country,additional_info.exiftool.FileType)
  #name <- paste0('l_',j) 
  name <- as.data.frame(nombre_l)
  name <- name[-length(name)]
#  assign(paste0('l_',j) , nombre_l)
  
  df <- rbind(df, name)
  
  
  j <- j+1
}

```
Con esto hemos preprocesado todos los archivos json y los metemos en un data frame. Hemos seleccionado
las variables que creemos mas relevantes.

Finalmente, mostramos el dataset resultante y lo guardamos como un .csv para tenerlo a mano.
```{r}

kable(df, booktabs = TRUE) %>%
  kable_styling(font_size = 10)
#write.csv(df,"~/GitHub/VirusTotal/ProyectoVT/Proyecto/virusTotal.csv", row.names = FALSE)## Importar dataset
write.csv(df, "~/LCC/ProyectoVT/Proyecto/virusTotal.csv")
```

