--- 
title: "Virus Total"
author: "Samuel Sánchez Toca y Alejandro Medina Astorga"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  Este libro de bookdown contiene el proyecto LCC sobre analizar el dataset de VirusTotal.
link-citations: yes
github-repo: https://github.com/samuel-uma/ProyectoVT
---

# Preprocesado de datos

Este es el proyecto realizado por Samuel Sánchez Toca y Alejandro Medina Astorga para la asignatura Laboratorio de Computación Científica para el dataset **VirusTotal**.

## Inicio 

Primero tuvimos que preprocesar los datos que venían en formato *json*, por lo que tuvimos que extraerlos y decidir qué información iba a resultar más útil para su analisis.

Para el preprocesado, hemos usado las librerías *jsonlite, tidyjson, jsonlite* y *tidyverse* para manejar los archivos. El dataset consta de casi doscientos ficheros con la información obtenida al analizarlos con distintos antivirus, el primer paso es, por tanto, ver cómo están estructurados los datos para decidir con qué información nos vamos a quedar.

## Renombrando los archivos

El siguiente *script* cambia los nombres a los archivos para facilitar su uso para hacer pruebas:

```
a=1
for i in *.json; do
	new=$(printf "%04d.json" "$a")
	mv -i -- "$i" "$new"
	let a=a+1
done

```

## Datos iniciales

Primero, listamos los nombres de todos los archivos y los guardamos en la variable *nombres_ficheros*:

```{r eval=FALSE}
path <- "~/Documentos/LCC/ProyectoVT/Proyecto/Android2"
nombres_ficheros <- list.files(path)
```


Luego empezamos importando el primer fichero para ver su estructura y explorarlo para tener una idea de cómo comenzar el preprocesado y el análisis. Usando la función *read_json* de la librería *tidyjson* leemos el fichero y lo guardamos en una variable:

```{r eval=FALSE}
json_0001 <- tidyjson::read_json(paste0(path, "/0001.json"))
```


```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

## Preprocesado

La función que hemos usado para construir un dataframe es *spread_all*, que de forma recursiva convierte todos los clave valor del json en columnas.
```{r}
library(curl)
library(tidyjson)
library(dplyr)
library(purrr)
library(tidyverse)
library(kableExtra)
library(bookdown)

json_data <- tidyjson::read_json("~/Documentos/LCC/ProyectoVT/Proyecto/Android2/0001.json")

tbl <- json_data %>%
  spread_all()
tbl
```


Ahora vamos a hacer lo mismo pero con todos los ficheros de la carpeta:

```{r, eval=FALSE}
#path <- "~/GitHub/VirusTotal/ProyectoVT/Proyecto/Android2"
path <- "~/Documentos/LCC/ProyectoVT/Proyecto/Android2"
nombres_ficheros <- list.files(path)

j <- 0
df <- data.frame()
for (i in nombres_ficheros) {
  filepath <- file.path(path, paste0(i))
  i <- tidyjson::read_json(filepath)
  tbl <- i %>% spread_all(recursive = TRUE)
  nombre_l <- tbl %>%
    select(scan_date,first_seen,total,size,times_submitted,positives,
           submission.submitter_country,additional_info.exiftool.FileType)
  name <- as.data.frame(nombre_l)
  name <- name[-length(name)]
  df <- rbind(df, name)
  
  
  j <- j+1
}

```


Con esto hemos preprocesado todos los archivos json y los metemos en un data frame. Hemos seleccionado
las columnas *scan_date*, *first_seen*, *total*, *size*, *times_submitted*, *country*, *fileType*.


Finalmente, mostramos el dataset resultante y lo guardamos como un .csv para tenerlo a mano. 

```{r}

kable(df, booktabs = TRUE) %>%
  kable_styling(font_size = 10)
#write.csv(df,"~/GitHub/VirusTotal/ProyectoVT/Proyecto/virusTotal.csv", row.names = FALSE)## Importar dataset
write.csv(df, "~/Documentos/LCC/ProyectoVT/Proyecto/virusTotal.csv")
write.csv(df, "~/Documentos/LCC/ProyectoVT/Proyecto/virusTotalCap2.csv")
```

